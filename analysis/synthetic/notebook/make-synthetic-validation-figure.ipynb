{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import bnpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "\n",
    "from subprocess import Popen, PIPE\n",
    "from threading import Timer\n",
    "from scipy.stats import iqr, percentileofscore\n",
    "from statsmodels import robust\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "date = str(datetime.date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = '../data/TCGA-glioblastoma-multiforme-log2TPM1.tsv'\n",
    "\n",
    "nbl = pd.read_csv(pth, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = '../data/h.all.v6.2.symbols.gmt'\n",
    "\n",
    "gss = {}\n",
    "gss_mean_mean = {}\n",
    "gss_median_mean = {}\n",
    "gss_mean_mad = {}\n",
    "with open(pth) as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split()\n",
    "        gss[fields[0]] = fields[2:]\n",
    "        _mean = nbl.reindex(fields[2:]).dropna().mean(axis=1).mean()\n",
    "        gss_mean_mean[fields[0]] = _mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mformat = {'hydra': 'Hydra',\n",
    "           'ssgsea': 'ssGSEA',\n",
    "           'gsva': 'GSVA'}\n",
    "\n",
    "mcolor = {'hydra': '#003050',\n",
    "          'ssgsea': '#7096a0',\n",
    "          'gsva': '#b0b7a7'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fit(xdata):\n",
    "    #data = data.apply(lambda x: x - x.mean(), axis=1)\n",
    "    #data = data.T.values\n",
    "\n",
    "    #xdata = bnpy.data.XData(data)\n",
    "\n",
    "    gamma = 5.0\n",
    "    sF = 2.0\n",
    "    K = 2\n",
    "\n",
    "    hmodel, info_dict = bnpy.run(\n",
    "        xdata, 'DPMixtureModel', 'Gauss', 'memoVB',\n",
    "        output_path=('/tmp/%s/' % uuid.uuid4() +\n",
    "            'trymoves-K=%d-gamma=%s-ECovMat=%s*eye-moves=merge,shuffle/' % (\n",
    "                K, gamma, sF)),\n",
    "        nLap=1000, nTask=1, nBatch=1,\n",
    "        gamma0=gamma, sF=sF, ECovMat='eye',\n",
    "        K=K, initname='randexamplesbydist',\n",
    "        moves='birth,merge,delete,shuffle',\n",
    "        b_startLap=0,\n",
    "        m_startLap=2,\n",
    "        d_startLap=2,\n",
    "        doWriteStdOut=False)\n",
    "    \n",
    "    return hmodel, xdata\n",
    "\n",
    "def get_assignments(model, data):\n",
    "    \"\"\"\n",
    "    Takes model and data and classifies samples\n",
    "\n",
    "    Will label samples with -1 cluster if they do not\n",
    "    fit in any of the model components\n",
    "\n",
    "    :param model:\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    unclass = 1 - np.sum(model.allocModel.get_active_comp_probs())\n",
    "    # Get the sample assignments\n",
    "    LP = model.calc_local_params(data)\n",
    "    asnmts = []\n",
    "    for row in range(LP['resp'].shape[0]):\n",
    "        _max = np.max(LP['resp'][row, :])\n",
    "        if _max < unclass:\n",
    "            print 'Could not classify sample'\n",
    "            asnmts.append(-1)\n",
    "\n",
    "        else:\n",
    "            _arg = np.argmax(LP['resp'][row, :])\n",
    "            #print row\n",
    "            #print LP['resp'][row, :]\n",
    "            asnmts.append(_arg)\n",
    "\n",
    "    return asnmts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hydra_auc(hydra_dir, tag, gs, test):\n",
    "    model_pth = os.path.join(hydra_dir, \n",
    "                                 tag, \n",
    "                                 gs, \n",
    "                                 'MultivariateAnalysis', \n",
    "                                 gs)\n",
    "    \n",
    "    try:\n",
    "        model = bnpy.ioutil.ModelReader.load_model_at_prefix(model_pth,\n",
    "                                                         prefix=gs) \n",
    "    except IOError:\n",
    "        print (\"WARNING: Missing Model! \", gs, tag)\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    train_data_pth = os.path.join(hydra_dir, \n",
    "                                  tag, \n",
    "                                  gs, \n",
    "                                  'MultivariateAnalysis', \n",
    "                                  gs, \n",
    "                                  'training-data.tsv')\n",
    "    \n",
    "    train = pd.read_csv(train_data_pth, \n",
    "                        sep='\\t', \n",
    "                        index_col=0)\n",
    "        \n",
    "    train_mean = train.mean(axis=1)\n",
    "    train_center = train.sub(train_mean, axis=0)\n",
    "    train_xdata = bnpy.data.XData(train_center.values.T)\n",
    "    \n",
    "    model, xdata = fit(train_xdata)\n",
    "    #print model.allocModel.get_active_comp_probs()\n",
    "    \n",
    "    maxi = None\n",
    "    max_mean = None\n",
    "    for i in range(len(model.allocModel.get_active_comp_probs())):\n",
    "        mean = model.obsModel.get_mean_for_comp(i)\n",
    "        norm = np.linalg.norm(mean)\n",
    "        if norm > max_mean:\n",
    "            maxi = i\n",
    "            max_mean = norm\n",
    "    \n",
    "    test = test.reindex(train.index)\n",
    "    test_center = test.sub(train_mean, axis=0)\n",
    "    test_xdata = bnpy.data.XData(test_center.values.T)\n",
    "    \n",
    "    LP = model.calc_local_params(test_xdata)\n",
    "    probs = LP['resp']\n",
    "    asnmts = LP['resp'].argmax(axis=1)\n",
    "    \n",
    "    test_labels = []\n",
    "    for j, sample in enumerate(test.columns):\n",
    "        if 'active' in sample:\n",
    "            test_labels.append(1)\n",
    "            \n",
    "        elif 'normal' in sample:\n",
    "            test_labels.append(-1)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError()\n",
    "            \n",
    "    scores = probs[:, maxi].flatten()\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, scores, pos_label=1)\n",
    "    \n",
    "    return auc(fpr, tpr), fpr, tpr\n",
    "\n",
    "\n",
    "def get_ssgsea_auc(tag, gs, test, date):\n",
    "    ssgsea_pth = os.path.join('../data/output', date, 'ssGSEA', tag, gs)\n",
    "    ssgsea = pd.read_csv(ssgsea_pth, sep='\\t', index_col=0)\n",
    "    ssgsea.columns = [x.replace('.', '-') for x in ssgsea.columns]\n",
    "    \n",
    "    ssgsea_scores = []\n",
    "    for sample in ssgsea.columns:\n",
    "        score = ssgsea.loc[gs, sample]\n",
    "        perc = percentileofscore(ssgsea[sample].sort_values().values, score)\n",
    "        #ssgsea_scores.append((100 - perc) / 100.)\n",
    "        ssgsea_scores.append(score)\n",
    "        \n",
    "    test_labels = []\n",
    "    for j, sample in enumerate(test.columns):\n",
    "        if 'active' in sample:\n",
    "            test_labels.append(1)\n",
    "            \n",
    "        elif 'normal' in sample:\n",
    "            test_labels.append(-1)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError()\n",
    "        \n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, ssgsea_scores, pos_label=1)\n",
    "    return auc(fpr, tpr), fpr, tpr\n",
    "\n",
    "\n",
    "def get_gsva_auc(tag, gs, test, date):\n",
    "    gsva_pth = os.path.join('../data/output', date, 'GSVA', tag, gs)\n",
    "    gsva = pd.read_csv(gsva_pth, sep='\\t', index_col=0)\n",
    "    gsva.columns = [x.replace('.', '-') for x in gsva.columns]\n",
    "    \n",
    "    gsva_scores = []\n",
    "    for sample in gsva.columns:\n",
    "        score = gsva.loc[gs, sample]\n",
    "        perc = percentileofscore(gsva[sample].values, score)\n",
    "        #gsva_scores.append((100 - perc) / 100.)\n",
    "        gsva_scores.append(score)\n",
    "        \n",
    "    test_labels = []\n",
    "    for j, sample in enumerate(test.columns):\n",
    "        if 'active' in sample:\n",
    "            test_labels.append(1)\n",
    "            \n",
    "        elif 'normal' in sample:\n",
    "            test_labels.append(-1)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError()\n",
    "        \n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, gsva_scores, pos_label=1)\n",
    "    return auc(fpr, tpr), fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "aucs = {}\n",
    "aucs['hydra'] = {}\n",
    "aucs['ssgsea'] = {}\n",
    "aucs['gsva'] = {}\n",
    "\n",
    "# {method: {gs: {%DEG: eff: tpr}}}\n",
    "datar = {}\n",
    "for m in ['hydra', 'ssgsea', 'gsva']:\n",
    "    datar[m] = {}\n",
    "    for d in ['0.10', '0.25']:\n",
    "        datar[m][d] = {}\n",
    "        for e in ['0.25', '0.50', '0.75', '1.00', '1.50', '2.00', '2.50', '3.00']:\n",
    "            datar[m][d][e] = {}\n",
    "\n",
    "plot_df = pd.DataFrame(columns = ['method', 'gene-set', 'auc', 'gs_mean', 'effect', 'difffrac'])\n",
    "\n",
    "dates = ['2019-09-07', '2019-10-02']\n",
    "for date in dates:\n",
    "    input_dir = os.path.join('../data/input', date)\n",
    "    output_dir = os.path.join('../data/output', date)\n",
    "    hydra_dir = os.path.join(output_dir, 'Hydra')\n",
    "\n",
    "    train_pths = os.path.join('../data/input', date, '*train*eff-*')\n",
    "    regex = re.compile('(?P<gs>HALLMARK_\\w*).*-eff-(?P<eff>\\d\\.\\d*)-diff-(?P<diff>\\d\\.\\d*)-frac-(?P<frac>\\d\\.\\d*)')\n",
    "    for _pth in glob.glob(train_pths):\n",
    "        print _pth \n",
    "        m = regex.search(_pth)\n",
    "        if not m:\n",
    "            raise ValueError()\n",
    "        \n",
    "        tag = \"eff-%s-diff-%s-frac-%s\" % m.groups()[1:]\n",
    "        exp = pd.read_csv(_pth, sep='\\t', index_col=0)  \n",
    "        gs = m.group('gs')\n",
    "        print gs, tag\n",
    "    \n",
    "        # Pull in degs\n",
    "        deg_pth = os.path.join(input_dir, 'synthetic-%s-degs-%s-%s.tsv' % (gs, tag, date))   \n",
    "        degs = []\n",
    "        with open(deg_pth, 'r') as f:\n",
    "            for line in f:\n",
    "                degs.append(line.strip())   \n",
    "    \n",
    "        test = pd.read_csv(_pth.replace('train', 'test'), \n",
    "                           sep='\\t', \n",
    "                           index_col=0)\n",
    "    \n",
    "        try:\n",
    "            # Hydra\n",
    "            aucs['hydra'][gs], fpr, tpr = get_hydra_auc(hydra_dir, tag, gs, test)\n",
    "            plot_df.loc[len(plot_df), :] = ['Hydra', \n",
    "                                            gs, \n",
    "                                            aucs['hydra'][gs], \n",
    "                                            gss_mean_mean[gs], \n",
    "                                            m.group('eff'),\n",
    "                                            m.group('diff')]\n",
    "            print 'Hydra AUC: ', aucs['hydra'][gs]\n",
    "            datar['hydra'][m.group('diff')][m.group('eff')][gs] = (fpr, tpr)\n",
    "    \n",
    "            # ssGSEA\n",
    "            aucs['ssgsea'][gs], fpr, tpr = get_ssgsea_auc(tag, gs, test, date)\n",
    "            plot_df.loc[len(plot_df), :] = ['ssGSEA', gs, aucs['ssgsea'][gs], gss_mean_mean[gs], m.group('eff'),\n",
    "                                            m.group('diff')]\n",
    "            print 'ssGSEA AUC: ', aucs['ssgsea'][gs]\n",
    "            datar['ssgsea'][m.group('diff')][m.group('eff')][gs] = (fpr, tpr)\n",
    "    \n",
    "            # GSVA\n",
    "            aucs['gsva'][gs], fpr, tpr = get_gsva_auc(tag, gs, test, date)\n",
    "            plot_df.loc[len(plot_df), :] = ['GSVA', gs, aucs['gsva'][gs], gss_mean_mean[gs], m.group('eff'),\n",
    "                                    m.group('diff')]\n",
    "            print 'GSVA AUC: ', aucs['gsva'][gs]\n",
    "            datar['gsva'][m.group('diff')][m.group('eff')][gs] = (fpr, tpr)\n",
    "        \n",
    "        except IOError:\n",
    "            print(\"Missing: \", gs)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df['auc'] = pd.to_numeric(plot_df['auc'])\n",
    "plot_df['gs_mean'] = pd.to_numeric(plot_df['gs_mean'])\n",
    "plot_df['effect'] = pd.to_numeric(plot_df['effect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['#0e3b59', '#7096a0', '#b0b7a7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.loc[pd.isna(plot_df['auc']), ['gene-set', 'effect', 'difffrac']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_gs = plot_df.loc[pd.isna(plot_df['auc']), ['gene-set', 'effect', 'difffrac']]\n",
    "\n",
    "for i, gs, eff, diff in lost_gs.itertuples():\n",
    "    mask = (plot_df['gene-set'] == gs) & (plot_df['effect'] == eff) & (plot_df['difffrac'] == diff)\n",
    "    plot_df = plot_df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.loc[plot_df['difffrac'] == '0.10', '%DEG'] = '10%'\n",
    "plot_df.loc[plot_df['difffrac'] == '0.25', '%DEG'] = '25%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    import scipy\n",
    "    import numpy as np\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m - h, m + h\n",
    "\n",
    "def mean_confidence_interval2(data, confidence=0.95):\n",
    "    import scipy\n",
    "    import numpy as np\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Hydra: ', mean_confidence_interval( plot_df.loc[(plot_df['method'] == 'Hydra'), 'auc'] )\n",
    "print 'ssGSEA: ', mean_confidence_interval( plot_df.loc[(plot_df['method'] == 'ssGSEA'), 'auc'] )\n",
    "print 'GSVA: ', mean_confidence_interval( plot_df.loc[(plot_df['method'] == 'GSVA'), 'auc'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style='white', font_scale=1.5)\n",
    "\n",
    "# based on:\n",
    "# https://stats.stackexchange.com/questions/186337/average-roc-for-repeated-10-fold-cross-validation-with-probability-estimates\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "base_fpr = np.linspace(0, 1, 101)\n",
    "\n",
    "diff_ind = {'0.10': 0, '0.25': 1}\n",
    "\n",
    "for color, method, name in zip(palette,\n",
    "                               ['hydra', 'ssgsea', 'gsva'],\n",
    "                               ['Hydra', 'ssGSEA', 'GSVA']):\n",
    "\n",
    "    for diff, l1 in datar[method].items():\n",
    "        tprs = None\n",
    "        for eff, l2 in l1.items():\n",
    "            if float(eff) < 1.0:\n",
    "                continue\n",
    "            for gs, (fpr, tpr) in l2.items():\n",
    "                mask = (plot_df['gene-set'] == gs) & (plot_df['effect'] == float(eff)) & (plot_df['difffrac'] == diff)\n",
    "                if len(plot_df[mask]) == 0:\n",
    "                    print('Skipping Lost Model', gs)\n",
    "                    print(plot_df[mask])\n",
    "                    continue\n",
    "                \n",
    "                #ax.plot(fpr, tpr, label=method)\n",
    "                btpr = np.interp(base_fpr, fpr, tpr)\n",
    "            \n",
    "                if tprs is None:\n",
    "                    tprs = btpr\n",
    "            \n",
    "                else:\n",
    "                    tprs = np.vstack([btpr, tprs])\n",
    "                    \n",
    "        mean_tprs = tprs.mean(axis=0)\n",
    "        std = tprs.std(axis=0)\n",
    "    \n",
    "        ax[diff_ind[diff]].plot([0.] + base_fpr, \n",
    "                                [0.] + mean_tprs, \n",
    "                                color, \n",
    "                                label=name,\n",
    "                                linewidth=2.5)\n",
    "\n",
    "for i in [0, 1]:\n",
    "    ax[i].plot([0, 1], [0, 1],'r--')\n",
    "    ax[i].set_xlim([-0.05, 1.02])\n",
    "    ax[i].set_ylim([-0.05, 1.02])\n",
    "\n",
    "    ax[i].set_ylabel(\"True Positive Rate\")\n",
    "    ax[i].set_xlabel(\"False Positive Rate\")\n",
    "    ax[i].set_aspect(\"equal\", 'datalim')\n",
    "    \n",
    "\n",
    "ax[0].set_title(\"%DEG = 10%\")\n",
    "ax[1].set_title(\"%DEG = 25%\")\n",
    "\n",
    "#plt.title('Mean ROC Curve for HALLMARK Gene Sets')\n",
    "\n",
    "hy1, hy2 = mean_confidence_interval2(plot_df.loc[(plot_df['method'] == 'Hydra') & (plot_df['%DEG'] == '10%') , 'auc'])\n",
    "ss1, ss2 = mean_confidence_interval2(plot_df.loc[(plot_df['method'] == 'ssGSEA') & (plot_df['%DEG'] == '10%'), 'auc'])\n",
    "gs1, gs2 = mean_confidence_interval2(plot_df.loc[(plot_df['method'] == 'GSVA') & (plot_df['%DEG'] == '10%'), 'auc'])\n",
    "\n",
    "L = ax[0].legend(title='Method', \n",
    "                 frameon=False,\n",
    "                 bbox_to_anchor=(0.35, 0.45))\n",
    "\n",
    "L.get_texts()[0].set_text(\"Hydra ($%.2f \\pm %.2f$)\" % (hy1, hy2))\n",
    "L.get_texts()[1].set_text(\"ssGSEA ($%.2f \\pm %.2f$)\" % (ss1, ss2))\n",
    "L.get_texts()[2].set_text(\"GSVA ($%.2f \\pm %.2f$)\" % (gs1, gs2))\n",
    "\n",
    "hy1, hy2 = mean_confidence_interval2(plot_df.loc[(plot_df['method'] == 'Hydra') & (plot_df['%DEG'] == '25%') , 'auc'])\n",
    "ss1, ss2 = mean_confidence_interval2(plot_df.loc[(plot_df['method'] == 'ssGSEA') & (plot_df['%DEG'] == '25%'), 'auc'])\n",
    "gs1, gs2 = mean_confidence_interval2(plot_df.loc[(plot_df['method'] == 'GSVA') & (plot_df['%DEG'] == '25%'), 'auc'])\n",
    "\n",
    "L = ax[1].legend(title='Method', \n",
    "                 frameon=False,\n",
    "                 bbox_to_anchor=(0.35, 0.45))\n",
    "\n",
    "L.get_texts()[0].set_text(\"Hydra ($%.2f \\pm %.2f$)\" % (hy1, hy2))\n",
    "L.get_texts()[1].set_text(\"ssGSEA ($%.2f \\pm %.2f$)\" % (ss1, ss2))\n",
    "L.get_texts()[2].set_text(\"GSVA ($%.2f \\pm %.2f$)\" % (gs1, gs2))\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "pth = '../img/ROC-plot-per-diff.svg'\n",
    "plt.savefig(pth, format='svg', bbox_inches='tight')\n",
    "\n",
    "pth = '../img/ROC-plot-per-diff.png'\n",
    "plt.savefig(pth, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white', font_scale=1.5)\n",
    "\n",
    "g = sns.catplot(x='effect', \n",
    "                y='auc',\n",
    "                hue='method',\n",
    "                col='%DEG',\n",
    "                col_order=['10%', '25%'],\n",
    "                kind='point',\n",
    "                data=plot_df,\n",
    "                palette=palette,\n",
    "                scatter_kws={'alpha': 1.0},\n",
    "                line_kws={'alpha': 1.0},\n",
    "                sharex=False,\n",
    "                sharey=False,\n",
    "                legend=False,\n",
    "                aspect=1.2)\n",
    "\n",
    "axes = g.axes\n",
    "\n",
    "for row in axes:\n",
    "    for ax in row:\n",
    "        ax.set_ylim(0.4, 1.1)\n",
    "        ax.set_xlabel('Effect Size')\n",
    "        ax.set_ylabel('AUC')\n",
    "        ax.set_yticks([0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "plt.legend(title='Method', frameon=False, loc=(0.6, 0.1))\n",
    "        \n",
    "pth = '../img/auc-vs-eff.svg'\n",
    "plt.savefig(pth, format='svg', bbox_inches='tight')\n",
    "\n",
    "pth = '../img/auc-vs-eff.png'\n",
    "plt.savefig(pth, format='png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
