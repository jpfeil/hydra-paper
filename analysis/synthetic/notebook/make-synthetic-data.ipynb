{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import shutil\n",
    "import getpass\n",
    "import multiprocessing\n",
    "\n",
    "from subprocess import Popen, PIPE\n",
    "from threading import Timer\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from scipy.stats import random_correlation\n",
    "\n",
    "date = str(datetime.date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changelog\n",
    "\n",
    "There is a bug in how hydra is writing out the final model. This makes it impossible to refit the model. I've added a check to make sure the pipeline writes everything out correctly.\n",
    "\n",
    "I've also added random subtype fraction values to avoid the criticism that I did not pick fair parameters.\n",
    "\n",
    "The othere diseases are adult cancers, but glioblastoma multiforme is also a pediatric cancer so I think this disease is more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False\n",
    "CPU = multiprocessing.cpu_count() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = 'data/TCGA-glioblastoma-multiforme-log2TPM1.tsv'\n",
    "exp = pd.read_csv(pth, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16764, 166)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno    \n",
    "import os\n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = 'data/h.all.v6.2.symbols.gmt'\n",
    "mapper = {}\n",
    "gs_genes = set()\n",
    "with open(pth) as f:\n",
    "    for line in f:\n",
    "        elements = line.strip().split('\\t')\n",
    "        name = elements[0]\n",
    "        if 'HALLMARK' in name:\n",
    "            desc = elements[1]\n",
    "            genes = elements[2:]\n",
    "            mapper[name] = [g for g in genes if g in exp.index.values]\n",
    "            gs_genes.update(mapper[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohend(d1, d2):\n",
    "    \"\"\"\n",
    "    https://machinelearningmastery.com/effect-size-measures-in-python/\n",
    "    \"\"\"\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "    # calculate the variance of the samples\n",
    "    s1, s2 = np.var(d1, ddof=1), np.var(d2, ddof=1)\n",
    "    # calculate the pooled standard deviation\n",
    "    s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = np.mean(d1), np.mean(d2)\n",
    "    # calculate the effect size\n",
    "    return (u1 - u2) / s\n",
    "\n",
    "def run(cmd, timeout_sec=900):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/1191374/using-module-subprocess-with-timeout\n",
    "    :param cmd:\n",
    "    :param timeout_sec:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    proc = Popen(cmd, stdout=PIPE, stderr=PIPE)\n",
    "    timer = Timer(timeout_sec, proc.kill)\n",
    "\n",
    "    try:\n",
    "        timer.start()\n",
    "        stdout, stderr = proc.communicate()\n",
    "\n",
    "    finally:\n",
    "        timer.cancel()\n",
    "\n",
    "    return stdout, stderr\n",
    "\n",
    "def run_hydra(data_pth, gs, database, output):\n",
    "    cmd = ['docker',\n",
    "           'run',\n",
    "           '-v', '%s:/data' % os.getcwd(),\n",
    "           'jpfeil/hydra@sha256:de39cd5b3b04b4ff87e8751084a21e743f25af431048bddbfe2faded05268467',\n",
    "           'sweep',\n",
    "           '-e', data_pth,\n",
    "           '--gmt', database,\n",
    "           '--gmt-regex', gs,\n",
    "           '--min-prob-filter', '0.05',\n",
    "           '--min-mean-filter', '1.0',\n",
    "           '--min-gene-filter', '1',\n",
    "           '--sensitive',\n",
    "           '--gamma', '5.00',\n",
    "           '--sF', '2.0',\n",
    "           '-K', '2',\n",
    "           '--CPU', str(CPU),\n",
    "           '--debug',\n",
    "           '--output-dir', output]\n",
    "    \n",
    "    stdout, stderr = run(cmd)\n",
    "    \n",
    "    assert os.path.exists(output)\n",
    "    \n",
    "    return stdout, stderr\n",
    "    \n",
    "def run_gsea(data_pth, output_pth, database):\n",
    "    cmd = ['docker',\n",
    "           'run',\n",
    "           '-v', '%s:/data' % os.getcwd(),\n",
    "           'jpfeil/pyrwrapper@sha256:a765a8f284c94b7791cfe87b8b83b34594a609873bca755b2fb83e45b5dd56fc',\n",
    "           'GSEA-manager.py',\n",
    "           data_pth, \n",
    "           output_pth,\n",
    "           database]\n",
    "    \n",
    "    stdout, stderr = run(cmd)\n",
    "    assert os.path.exists(output_pth)\n",
    "    return stdout, stderr\n",
    "\n",
    "\n",
    "def AlmightyCorrcoefEinsumOptimized(O, P):\n",
    "    \"\"\"\n",
    "    https://github.com/ikizhvatov/efficient-columnwise-correlation/blob/master/columnwise_corrcoef_perf.py\n",
    "    \"\"\"\n",
    "    (n, t) = O.shape      # n traces of t samples\n",
    "    (n_bis, m) = P.shape  # n predictions for each of m candidates\n",
    "\n",
    "    DO = O - (np.einsum(\"nt->t\", O, optimize='optimal') / np.double(n)) # compute O - mean(O)\n",
    "    DP = P - (np.einsum(\"nm->m\", P, optimize='optimal') / np.double(n)) # compute P - mean(P)\n",
    "\n",
    "    cov = np.einsum(\"nm,nt->mt\", DP, DO, optimize='optimal')\n",
    "\n",
    "    varP = np.einsum(\"nm,nm->m\", DP, DP, optimize='optimal')\n",
    "    varO = np.einsum(\"nt,nt->t\", DO, DO, optimize='optimal')\n",
    "    tmp = np.einsum(\"m,t->mt\", varP, varO, optimize='optimal')\n",
    "    return cov / np.sqrt(tmp)\n",
    "    \n",
    "    \n",
    "def corr2cov(corr, std):\n",
    "    return corr * np.outer(std, std)\n",
    "\n",
    "def get_data(genes, targets, size, \n",
    "             eff, pdiff, ptype, mu, cov):\n",
    "    \n",
    "    print(\"Creating test data...\")\n",
    "    ssize = int(ptype * size)\n",
    "    bsize = size - ssize\n",
    "    \n",
    "    bsamples = ['normal%d' % x for x in range(bsize)]\n",
    "    ssamples = ['active%d' % x for x in range(bsize, size)]\n",
    "\n",
    "    samples = bsamples + ssamples\n",
    "    \n",
    "    assert len(samples) == size\n",
    "    \n",
    "    print(\"Sampling from TRAIN multivariate normal\")\n",
    "    train = pd.DataFrame(index=genes,\n",
    "                         columns=samples,\n",
    "                         data=np.random.multivariate_normal(mu, \n",
    "                                                            cov, \n",
    "                                                            size).T)\n",
    "    \n",
    "    print(\"Sampling from TEST multivariate normal\")\n",
    "    test = pd.DataFrame(index=genes,\n",
    "                        columns=samples,\n",
    "                        data=np.random.multivariate_normal(mu, cov, size).T)\n",
    "    \n",
    "    print(\"Randomly sampling DEGs\")\n",
    "    degs = np.random.choice(targets, \n",
    "                            int(pdiff * len(targets)), \n",
    "                            replace=False)\n",
    "    \n",
    "    print(\"Randomly sampling covariance matrix\")\n",
    "    _cov = make_spd_matrix(len(degs), len(degs))\n",
    "    \n",
    "    print(\"Creating subtype mean expression vector\")\n",
    "    m2 = []\n",
    "    for i, gene in enumerate(degs):\n",
    "        p1 = (bsize - 1) * (std[gene] ** 2)\n",
    "        p2 = (ssize - 1) * _cov[i, i]\n",
    "        s = np.sqrt( (p1 + p2) / (size - 2) )\n",
    "        _m2 = mu[gene] + eff * s\n",
    "        m2.append(_m2)\n",
    "    \n",
    "    print(\"Adding TRAIN subtyping mean signal\")\n",
    "    train.loc[degs, ssamples] = np.random.multivariate_normal(m2, _cov, ssize).T\n",
    "    \n",
    "    print(\"Adding TEST subtyping mean signal\")\n",
    "    test.loc[degs, ssamples] = np.random.multivariate_normal(m2, _cov, ssize).T\n",
    "    for gene in degs[:5]:\n",
    "        bins = np.linspace(0, 10, 25)\n",
    "        sns.distplot(train.loc[gene, bsamples], \n",
    "                     kde=False,\n",
    "                     label='background',\n",
    "                     bins=bins)\n",
    "        sns.distplot(train.loc[gene, ssamples], \n",
    "                     kde=False,\n",
    "                     label='active',\n",
    "                     bins=bins)\n",
    "        plt.show()\n",
    "        \n",
    "    cds = []\n",
    "    for gene in degs:\n",
    "        cd = cohend(train.loc[gene, ssamples].values,\n",
    "                    train.loc[gene, bsamples].values)\n",
    "        cds.append(cd)\n",
    "    return train, test, degs, np.mean(cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(in_dir, out_dir, gs, gs_genes, data, \n",
    "             effect, percent_diff, mu, cov, size=300):\n",
    "    \n",
    "    # One criticism was that I picked too many magic \n",
    "    # numbers, so here I'm going to pick a random number\n",
    "    subtype_frac = round(random.uniform(0.15, 0.4), 2)\n",
    "    \n",
    "    tag = 'eff-%.2f-diff-%.2f-frac-%.2f' % (effect, \n",
    "                                            percent_diff, \n",
    "                                            subtype_frac)\n",
    "    print(tag)\n",
    "    \n",
    "    train_pth = os.path.join(in_dir, \n",
    "                             'synthetic-%s-train-%s-%s.tsv' % (gs, \n",
    "                                                                 tag, \n",
    "                                                                 date))\n",
    "    \n",
    "    test_pth = os.path.join(in_dir, \n",
    "                            'synthetic-%s-test-%s-%s.tsv' % (gs, \n",
    "                                                                tag, \n",
    "                                                                date))\n",
    "    \n",
    "    \n",
    "    deg_pth = os.path.join(in_dir,\n",
    "                           'synthetic-%s-degs-%s-%s.tsv' % (gs, \n",
    "                                                            tag,\n",
    "                                                            date))\n",
    "    \n",
    "    cohen_pth = os.path.join(in_dir, \n",
    "                             'synthetic-%s-cohen-%s-%s.tsv' % (gs, \n",
    "                                                               tag,\n",
    "                                                               date))\n",
    "    \n",
    "    \n",
    "    train, test, degs, cohen = get_data(mu.index.values, \n",
    "                                        gs_genes,\n",
    "                                        size, \n",
    "                                        effect, \n",
    "                                        percent_diff, \n",
    "                                        subtype_frac,\n",
    "                                        mu, cov)\n",
    "    \n",
    "        \n",
    "    train.to_csv(train_pth, sep='\\t')\n",
    "    test.to_csv(test_pth, sep='\\t')\n",
    "    \n",
    "    with open(deg_pth, 'w') as f:\n",
    "        f.write('\\n'.join(degs))\n",
    "        \n",
    "    with open(cohen_pth, 'w') as f:\n",
    "        f.write(str(cohen))\n",
    "    \n",
    "    hydra_pth = os.path.join(out_dir, 'Hydra', tag, gs)\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    stdout, stderr = run_hydra(train_pth, gs, 'data/h.all.v6.2.symbols.gmt', hydra_pth)\n",
    "    toc = time.perf_counter()\n",
    "    \n",
    "    time_dir = os.path.join(out_dir, 'TIME', 'Hydra', tag)\n",
    "    mkdir_p(time_dir)\n",
    "    time_pth = os.path.join(time_dir, gs)\n",
    "    with open(time_pth, 'w') as f:\n",
    "        f.write(str(toc - tic))\n",
    "    \n",
    "    gsea_pth = os.path.join(out_dir)\n",
    "    run_gsea(test_pth, gsea_pth, 'data/h.all.v6.2.symbols.gmt')\n",
    "    \n",
    "\n",
    "def run_validation(in_dir,\n",
    "                   out_dir,\n",
    "                   data, \n",
    "                   gene_sets, \n",
    "                   effects, \n",
    "                   percent_diffs,\n",
    "                   mu, cov):   \n",
    "    \n",
    "    for effect in effects:\n",
    "        for percent_diff in percent_diffs:\n",
    "            # Sample gene sets to save time\n",
    "            if len(gene_sets) > 20:\n",
    "                gs_subsets = random.sample(gene_sets.keys(), k=20)\n",
    "            \n",
    "            else:\n",
    "                gs_subsets = gene_sets.keys()\n",
    "            for gs in gs_subsets:\n",
    "                validate(in_dir, \n",
    "                         out_dir,\n",
    "                         gs, \n",
    "                         gene_sets[gs],\n",
    "                         data, \n",
    "                         effect, \n",
    "                         percent_diff,\n",
    "                         mu, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    in_dir = 'test_input/%s' % date\n",
    "    out_dir = 'test_output/%s' % date\n",
    "    if os.path.exists(in_dir):\n",
    "        shutil.rmtree(in_dir)\n",
    "    if os.path.exists(out_dir):\n",
    "        shutil.rmtree(out_dir)\n",
    "    mkdir_p(in_dir)\n",
    "    mkdir_p(out_dir)\n",
    "    _exp = exp.reindex(mapper['HALLMARK_ESTROGEN_RESPONSE_EARLY']).dropna()\n",
    "    test = {'HALLMARK_ESTROGEN_RESPONSE_EARLY': [x for x in mapper['HALLMARK_ESTROGEN_RESPONSE_EARLY']]}\n",
    "    \n",
    "    # Need global parameters\n",
    "    mu = _exp.mean(axis=1)\n",
    "    std = _exp.std(axis=1)\n",
    "    corr = AlmightyCorrcoefEinsumOptimized(_exp.T, _exp.T)\n",
    "    cov = corr2cov(corr, std.values.reshape(len(std), 1))\n",
    "    \n",
    "    print(\"Staring Run...\")\n",
    "    run_validation(in_dir,\n",
    "                   out_dir,\n",
    "                   _exp, \n",
    "                   test,\n",
    "                   [1.5],\n",
    "                   [0.10, 0.25],\n",
    "                   mu, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eff-0.25-diff-0.25-frac-0.22\n",
      "Creating test data...\n",
      "Sampling from TRAIN multivariate normal\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9cdd59cb36f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                    \u001b[0;34m[\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                    \u001b[0;34m[\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                    mu, cov)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-22522aa527d7>\u001b[0m in \u001b[0;36mrun_validation\u001b[0;34m(in_dir, out_dir, data, gene_sets, effects, percent_diffs, mu, cov)\u001b[0m\n\u001b[1;32m     91\u001b[0m                          \u001b[0meffect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                          \u001b[0mpercent_diff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                          mu, cov)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-22522aa527d7>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(in_dir, out_dir, gs, gs_genes, data, effect, percent_diff, mu, cov, size)\u001b[0m\n\u001b[1;32m     39\u001b[0m                                         \u001b[0mpercent_diff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                         \u001b[0msubtype_frac\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                                         mu, cov)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-fe09f271e36a>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(genes, targets, size, eff, pdiff, ptype, mu, cov)\u001b[0m\n\u001b[1;32m    114\u001b[0m                          data=np.random.multivariate_normal(mu, \n\u001b[1;32m    115\u001b[0m                                                             \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                                                             size).T)\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sampling from TEST multivariate normal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/linalg/decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# perform decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,\n\u001b[0;32m--> 129\u001b[0;31m                           full_matrices=full_matrices, overwrite_a=overwrite_a)\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The real deal\n",
    "if not TEST:\n",
    "    in_dir = 'input/%s' % date\n",
    "    out_dir = 'output/%s' % date\n",
    "    mkdir_p(in_dir)\n",
    "    mkdir_p(out_dir)\n",
    "\n",
    "    with open(os.path.join(out_dir, 'V16'), 'a') as f:\n",
    "        f.write(date)\n",
    "\n",
    "    # Need global parameters\n",
    "    mu = exp.mean(axis=1)\n",
    "    std = exp.std(axis=1)\n",
    "    corr = AlmightyCorrcoefEinsumOptimized(exp.T, exp.T)\n",
    "    cov = corr2cov(corr, std.values.reshape(len(std), 1))\n",
    "\n",
    "    run_validation(in_dir, \n",
    "                   out_dir,\n",
    "                   exp, \n",
    "                   mapper,\n",
    "                   [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 2.5, 3.0],\n",
    "                   [0.25, 0.1],\n",
    "                   mu, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
