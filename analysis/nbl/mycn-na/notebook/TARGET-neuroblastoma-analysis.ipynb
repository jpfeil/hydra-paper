{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import uuid\n",
    "import tempfile\n",
    "import bnpy\n",
    "import scikit_posthocs as sp\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "from scipy.stats import kruskal, f_oneway\n",
    "\n",
    "sys.path.append('/opt/hydra/')\n",
    "\n",
    "src = os.environ[\"HYDRA_SRC\"]\n",
    "\n",
    "import library.analysis as hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='example.log',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cmd was used to identify multimodal genes \n",
    "cmd = [\"docker\" ,\n",
    "       \"run\",\n",
    "       \"-v\", \"$PWD:/data\",\n",
    "       \"jpfeil/hydra@sha256:123bee0aa2b3e63084c773a13a16d247076462af910a104cd5776ba5e6d4b29d\",\n",
    "       \"filter\",\n",
    "       \"-e\", \"data/target-high-risk-nbl-mycn-na-exp-2018-11-12.tsv\",\n",
    "       \"--output-dir\", \"output\",\n",
    "       \"--CPU\", \"15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_genes = '../data/output/MultiModalGenes/'\n",
    "exp_path = '../data/expression/target-high-risk-nbl-mycn-na-exp-2018-11-12.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in expression data\n",
    "exp = pd.read_csv(exp_path, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save list of multimodal genes\n",
    "mms = []\n",
    "for gene in os.listdir(mm_genes):\n",
    "    mms.append(gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan minimum probability thresholds\n",
    "if False:\n",
    "    scan = hy.ScanEnrichmentAnalysis(mm_genes, \n",
    "                                     exp_path, \n",
    "                                     'GO', \n",
    "                                     min_prob_range=[0.10, 0.15, 0.20, 0.25, 0.3], \n",
    "                                     CPU=7,\n",
    "                                     K=5).scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform enrichment analysis - same as enrich command\n",
    "res = hy.EnrichmentAnalysis(exp_path=exp_path,\n",
    "                            mm_path=mm_genes,\n",
    "                            min_prob_filter=0.2,\n",
    "                            gmt_path='GO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enriched gene set terms\n",
    "terms = res.get_enriched_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract enriched GO term genes\n",
    "genes = res.get_enriched_term_genes()\n",
    "\n",
    "len(genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform multivariate DP-GMM analysis\n",
    "clus = hy.MultivariateMixtureModel(data=exp.reindex(genes),\n",
    "                                   center=True,\n",
    "                                   gamma=5.0,\n",
    "                                   variance=2.0,\n",
    "                                   K=5, \n",
    "                                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format pathway names for printing\n",
    "def format_pathway(x):\n",
    "    fields = x.split('%')\n",
    "    return '%s (%s)' % (fields[0], fields[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GSEA on each cluster\n",
    "fgsea = clus.get_cluster_features(exp,\n",
    "                                  gmt='/opt/hydra/gene-sets/Human_GOBP_AllPathways_no_GO_iea_December_01_2018_symbol.gmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with enriched pathways\n",
    "fgsea_df = None\n",
    "for key, values in fgsea.items():\n",
    "    if fgsea_df is None:\n",
    "        header = pd.MultiIndex.from_product([list(fgsea.keys()), \n",
    "                                             ['padj', 'NES']],\n",
    "                                           names=['cluster', 'feature'])\n",
    "        \n",
    "        fgsea_df = pd.DataFrame(index=values.index.values, columns=header)\n",
    "        \n",
    "    print 'Key: ', key,\n",
    "    t = values.reset_index().reindex(['pathway', 'padj', 'NES'], axis=1)\n",
    "    t['pathway'] = t['pathway'].apply(format_pathway) \n",
    "    print(t[(t['NES'] > 0) & (t['padj'] < 0.05)].sort_values('NES', ascending=False).head(10))\n",
    "    \n",
    "    fgsea_df[(key, 'padj')] = values.loc[fgsea_df.index, 'padj'].values\n",
    "    fgsea_df[(key, 'NES')] = values.loc[fgsea_df.index, 'NES'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe for downstream analysis\n",
    "pth = '../data/TARGET-MYCN-NA-Pathways-Enrichment.tsv'\n",
    "fgsea_df.to_csv(pth, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create LaTEX tables with top 10 enriched pathways\n",
    "cpth = '../img/TARGET-MYCN-NA-top-10-pathways-cluster-%d.tex'\n",
    "for key, values in fgsea.items():\n",
    "    with pd.option_context('display.precision', 2):\n",
    "        t = values.reset_index().reindex(['pathway', 'padj', 'NES'], axis=1)\n",
    "        t['pathway'] = t['pathway'].apply(format_pathway)\n",
    "        with open(pth % key, 'w') as f:\n",
    "            #print(t[(t['NES'] > 0) & (t['padj'] < 0.05)].sort_values('NES', ascending=False).head(10).to_latex(index=False))\n",
    "            t[(t['NES'] > 0) & (t['padj'] < 0.05)].sort_values('NES', ascending=False).head(10).to_latex(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cluster assignments\n",
    "assignments = clus.get_assignments(exp.reindex(genes))\n",
    "\n",
    "assign = pd.DataFrame(index=exp.columns,\n",
    "                      columns=[1])\n",
    "\n",
    "for sample, assignment in zip(exp.columns, assignments):\n",
    "    assign.loc[sample, 1] = assignment + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save assignments\n",
    "assign.to_csv('../data/assignments.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peform hierarchical clustering on multimodal genes\n",
    "hclust = hy.HClust(data=exp.reindex(genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot row linkage with a distance of 17\n",
    "hclust.plot_row_linkage(17)\n",
    "row_groups = hclust.get_row_groups(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load M3C analysis\n",
    "pth = '../data/cluster-analysis/MYCN-NA-M3C-MAD-5000-labels-2.tsv'\n",
    "m3c5000 = pd.read_csv(pth, sep='\\t')\n",
    "m3c5000.index = [x.replace('.', '-') for x in m3c5000.index.values]\n",
    "m3c5000 = m3c5000.reindex(exp.columns)\n",
    "m3c5000.head()\n",
    "\n",
    "pth = '../data/cluster-analysis/MYCN-NA-M3C-MAD-500-labels-3.tsv'\n",
    "m3c500 = pd.read_csv(pth, sep='\\t')\n",
    "m3c500.index = [x.replace('.', '-') for x in m3c500.index.values]\n",
    "m3c500 = m3c500.reindex(exp.columns)\n",
    "m3c500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# M3C fgsea analysis\n",
    "m3c5000_feats = {}\n",
    "for cluster, rows in m3c5000.groupby('consensuscluster'):\n",
    "    ins = rows.index.values\n",
    "    outs = m3c5000[m3c5000['consensuscluster'] != cluster].index.values\n",
    "    \n",
    "    res = ttest_ind(exp[ins], exp[outs], axis=1).statistic\n",
    "    tstats = pd.DataFrame(index=exp.index, data=res).dropna()\n",
    "    tstats = tstats.sort_values(0, ascending=False)\n",
    "    \n",
    "    m3c5000_feats[cluster] = hy.n1(tstats, \n",
    "                                   gmt='/opt/hydra/gene-sets/Human_GOBP_AllPathways_no_GO_iea_December_01_2018_symbol.gmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m3c5000_feats[1]\n",
    "t[(t['padj'] < 0.05) & (t['ES'] > 0.0)].sort_values('NES', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m3c5000_feats[2]\n",
    "t[(t['padj'] < 0.05) & (t['ES'] > 0.0)].sort_values('NES', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# M3C fgsea analysis with a threshold of 500MAD\n",
    "m3c500_feats = {}\n",
    "for cluster, rows in m3c500.groupby('consensuscluster'):\n",
    "    ins = rows.index.values\n",
    "    outs = m3c500[m3c500['consensuscluster'] != cluster].index.values\n",
    "    \n",
    "    res = ttest_ind(exp[ins], exp[outs], axis=1).statistic\n",
    "    tstats = pd.DataFrame(index=exp.index, data=res).dropna()\n",
    "    tstats = tstats.sort_values(0, ascending=False)\n",
    "    \n",
    "    m3c500_feats[cluster] = hy.n1(tstats, \n",
    "                                  gmt='/opt/hydra/gene-sets/Human_GOBP_AllPathways_no_GO_iea_December_01_2018_symbol.gmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m3c500_feats[1]\n",
    "t[(t['padj'] < 0.05) & (t['ES'] > 0.0)].sort_values('NES', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m3c500_feats[2]\n",
    "t[(t['padj'] < 0.05) & (t['ES'] > 0.0)].sort_values('NES', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m3c500_feats[3]\n",
    "t[(t['padj'] < 0.05) & (t['ES'] > 0.0)].sort_values('NES', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = {0: 'r', 1:'b', 2:'g', 3:'y', 4: 'p'}\n",
    "\n",
    "col_colors = [cmap[i] for i in assignments]\n",
    "\n",
    "m3c5000_colors = [cmap[i] for i in m3c5000['consensuscluster'].values]\n",
    "\n",
    "m3c500_colors = [cmap[i] for i in m3c500['consensuscluster'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#col_order = assign.sort_values(1).index.values\n",
    "\n",
    "g = sns.clustermap(exp.reindex(genes).dropna(),\n",
    "                   z_score=0,\n",
    "                   method='ward',\n",
    "                   center=0,\n",
    "                   col_colors=[col_colors, m3c5000_colors, m3c500_colors],\n",
    "                   cmap=sns.diverging_palette(240, 10, n=7),\n",
    "                   figsize=(10, 10))\n",
    "\n",
    "ax = g.ax_heatmap\n",
    "\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xticks([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "pth = '../img/NBL-expression-heatmap.svg'\n",
    "plt.savefig(pth, format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate clusters with NBL clinical features\n",
    "pth = '../data/meta/target-features-v2.tsv'\n",
    "features = pd.read_csv(pth, sep='\\t')\n",
    "def feature_map(df, features):\n",
    "    \n",
    "    output = pd.DataFrame(columns=['cluster', \n",
    "                                   'sample', \n",
    "                                   'feature', \n",
    "                                   'value'])\n",
    "    \n",
    "    for cluster, rows in df.groupby(1):\n",
    "        roots = ['-'.join(s.split('-')[:3]) for s in rows['index'].values]\n",
    "        _f = features[features['root'].isin(roots)]\n",
    "        for feature, value in _f.iterrows():\n",
    "            output.loc[len(output), :] = [cluster, \n",
    "                                          value['root'], \n",
    "                                          value['feature'], \n",
    "                                          value['value']]\n",
    "    return output\n",
    "\n",
    "data = feature_map(assign.reset_index(),\n",
    "                   features)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "feature_clusters = pd.DataFrame(columns=['feature', 'value', 'cluster', 'fraction', 'count'])\n",
    "\n",
    "for (feature, value), rows in data.groupby(['feature', 'value']):\n",
    "    c = Counter(rows['cluster'].values)\n",
    "    for cluster, count in c.items():\n",
    "        frac = (count + 0.0) / sum(c.values())\n",
    "        feature_clusters.loc[len(feature_clusters), :] = [feature, \n",
    "                                                          value, \n",
    "                                                          cluster, \n",
    "                                                          frac, \n",
    "                                                          count]\n",
    "        \n",
    "        \n",
    "def _fisher(m):\n",
    "    temp = os.path.join(tempfile.gettempdir(), 'M' + str(uuid.uuid4()))\n",
    "    np.savetxt(temp, m, delimiter='\\t')\n",
    "    \n",
    "    cmd = ['Rscript',\n",
    "           os.path.join(src, 'bin', 'fisher.R'),\n",
    "           temp]\n",
    "    \n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n",
    "    \n",
    "    stdout, stderr = p.communicate()\n",
    "    \n",
    "    return float(stdout)\n",
    "        \n",
    "def fisher(feature, value, df, background=None, mod=None):\n",
    "    m = np.zeros((2, len(df['cluster'].unique())))\n",
    "    \n",
    "    for cluster, rows in df.groupby('cluster'):\n",
    "        m1 = (rows['feature'] == feature) & (rows['value'] == value) & (rows['value'] != 'unknown') & (~pd.isnull(rows['value']))\n",
    "        \n",
    "        if background is None:\n",
    "            m2 = (rows['feature'] == feature) & (rows['value'] != value) & (rows['value'] != 'unknown') & (~pd.isnull(rows['value']))\n",
    "            \n",
    "            #print rows[m2]\n",
    "        \n",
    "        else:\n",
    "            m2 = (rows['feature'] == feature) & (rows['value'] == background) & (rows['value'] != 'unknown') & (~pd.isnull(rows['value']))\n",
    "        \n",
    "        n1 = rows[m1].shape[0]\n",
    "        n2 = rows[m2].shape[0]\n",
    "        \n",
    "        # 1-indexed\n",
    "        m[0, cluster - 1] += n1\n",
    "        m[1, cluster - 1] += n2\n",
    "        \n",
    "    if m[0, :].sum() > m[1, :].sum():\n",
    "        print(\"WARNING: Feature count is greater than background!\")\n",
    "    \n",
    "    if mod is not None:\n",
    "        for i, v in enumerate(mod):\n",
    "            m[0, i] += v\n",
    "        \n",
    "    nr, nc = m.shape\n",
    "\n",
    "    return _fisher(m), m\n",
    "\n",
    "\n",
    "features.loc[features['feature'] == '%tumor', 'value'] = pd.to_numeric(features.loc[features['feature'] == '%tumor', 'value'])\n",
    "\n",
    "features.loc[features['feature'] == 'age', 'value'] = pd.to_numeric(features.loc[features['feature'] == 'age', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = pd.DataFrame(columns=['feature', \n",
    "                           'alteration', \n",
    "                           'p-value',\n",
    "                           'cluster1',\n",
    "                           'cluster2',\n",
    "                           'cluster3',\n",
    "                           'background1',\n",
    "                           'background2',\n",
    "                           'background3'])\n",
    "\n",
    "molecular_features = [('ATRX', 'deleted', None), \n",
    "                      ('ALK', 'mutated', None),\n",
    "                      ('1q+', 'gain', None),\n",
    "                      ('1p-', 'loss', None),\n",
    "                      ('11q-', 'loss', None),\n",
    "                      ('17q+', 'gain', None),\n",
    "                      ('MKI', 'low', None),\n",
    "                      ('MKI', 'intermediate', None),\n",
    "                      ('MKI', 'high', None),\n",
    "                      ('Grade', 'differentiating', None)]\n",
    "\n",
    "for feature, alteration, background in molecular_features:\n",
    "    print feature, alteration\n",
    "    p, m = fisher(feature, alteration, data, background=background)\n",
    "    print p\n",
    "    print m\n",
    "    \n",
    "    mf.loc[len(mf), :] = [feature, alteration, p] + list(m.flatten())\n",
    "\n",
    "mf.sort_values('p-value').to_csv('../data/meta/molecular-feature-table.tsv', \n",
    "                                 sep='\\t',\n",
    "                                 index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TME profiling tools\n",
    "pth = '../data/immune/CIBERSORT.Output_Job17-target-mycn-na.txt'\n",
    "ciber = pd.read_csv(pth, index_col=0, sep='\\t')\n",
    "\n",
    "pth = '../data/immune/mycn-na-target-estimate.tsv'\n",
    "est = pd.read_csv(pth, sep='\\t', comment='#', header=1, index_col=0)\n",
    "est.drop('Description', axis=1, inplace=True)\n",
    "est.columns = [x.replace('.', '-') for x in est.columns]\n",
    "\n",
    "pth = '../data/immune/xCell_target-high-risk-nbl-mycn-na-exp-2018-11-12_xCell_1754032119.txt'\n",
    "xcell = pd.read_csv(pth, sep='\\t', index_col=0)\n",
    "xcell.columns = [x.replace('.', '-') for x in xcell.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TME profiling data in dataframe\n",
    "immune_groups = dict((group, []) for group in assign[1].unique())\n",
    "immune = pd.DataFrame(columns=['sample', 'cluster', 'source', 'feature', 'value'])\n",
    "for sample in assign.index.values:\n",
    "    if sample not in ciber.index.values:\n",
    "        print 'Misisng: ', sample\n",
    "        continue\n",
    "        \n",
    "    assignment = assign.loc[sample, 1]\n",
    "    \n",
    "    immune_groups[assignment].append(sample)\n",
    "    \n",
    "    for score in ['StromalScore', 'ImmuneScore', 'ESTIMATEScore']:\n",
    "        _est = est.loc[score, sample].item()\n",
    "        immune.loc[len(immune), :] = [sample, assignment, 'Estimate', score, _est]\n",
    "        \n",
    "    immune.loc[len(immune), :] = [sample, assignment, \n",
    "                                'Estimate', 'TumorPurity', \n",
    "                                np.cos(0.6049872018 + 0.0001467884 * _est)]\n",
    "    \n",
    "    pvalue = ciber.loc[sample, 'P-value'].item()\n",
    "    for cell, value in ciber.loc[sample, :].iteritems():\n",
    "        immune.loc[len(immune), :] = [sample, assignment, 'CIBERSORT', cell, value]\n",
    "        \n",
    "    for cell, value in xcell[sample].iteritems():\n",
    "        immune.loc[len(immune), :] = [sample, assignment, 'xCell', cell, value]\n",
    "\n",
    "skip = ['P-value', 'Pearson Correlation', 'RMSE']        \n",
    "immune = immune[~immune['feature'].isin(skip)]        \n",
    "immune['value'] = pd.to_numeric(immune['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify statistically significant correlations\n",
    "sigs = collections.defaultdict(list)\n",
    "\n",
    "p_values = pd.DataFrame(columns=['source', \n",
    "                                 'feature', \n",
    "                                 'A', \n",
    "                                 'B', \n",
    "                                 'holm p-value'])\n",
    "\n",
    "for source, rows in immune.groupby('source'):\n",
    "    print source\n",
    "    nfeatures = len(rows['feature'].unique())\n",
    "    alpha = 1 - (1 - 0.05) ** (1.0 / nfeatures)\n",
    "    for feature in rows['feature'].unique():\n",
    "        print(feature)\n",
    "        groups3 = []\n",
    "        for i, rows in immune[immune['feature'] == feature].groupby('cluster'):\n",
    "            groups3.append(list(rows['value'].values))\n",
    "            print i, rows['value'].mean()\n",
    "    \n",
    "        try:\n",
    "            stat, pvalue = kruskal(*groups3)\n",
    "            print(feature, pvalue, pvalue < alpha)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print e\n",
    "            continue\n",
    "    \n",
    "        if pvalue < alpha:\n",
    "            sigs[source].append(feature)\n",
    "            \n",
    "            try:\n",
    "                res = sp.posthoc_mannwhitney(groups3, \n",
    "                                             p_adjust='holm')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print e\n",
    "                continue\n",
    "            \n",
    "            for i, j in itertools.combinations(range(len(groups3)),\n",
    "                                               2):\n",
    "                \n",
    "                if i == j:\n",
    "                    continue \n",
    "                    \n",
    "                p_values.loc[len(p_values), :] = [source,\n",
    "                                                  feature,\n",
    "                                                  i, \n",
    "                                                  j,\n",
    "                                                  res.iloc[i, j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot significant enrichment CIBERSORT\n",
    "sns.set(font_scale=1.5, style='white')\n",
    "\n",
    "mask = (immune['source'] == 'CIBERSORT') & (immune['feature'].isin(sigs['CIBERSORT']))\n",
    "\n",
    "t = immune[mask]\n",
    "\n",
    "g = sns.catplot(x='cluster', \n",
    "                y='value', \n",
    "                col='feature',\n",
    "                kind='box',\n",
    "                col_wrap=3,\n",
    "                color='white',\n",
    "                sharex=False,\n",
    "                sharey=False,\n",
    "                data=t,\n",
    "                aspect=1.25)\n",
    "\n",
    "for i, feature in enumerate(t['feature'].unique()):\n",
    "    print i, feature\n",
    "    sns.swarmplot(x='cluster',\n",
    "                  y='value',\n",
    "                  color='k',\n",
    "                  size=5,\n",
    "                  data=t[t['feature'] == feature],\n",
    "                  ax=g.axes[i])\n",
    "\n",
    "for i in range(len(g.axes)):\n",
    "    g.axes[i].set_xlabel('Hydra Cluster')\n",
    "    g.axes[i].set_ylabel('CIBERSORT Score')\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "\n",
    "pth = '../img/CIBERSORT-Plots.svg'\n",
    "plt.savefig(pth, format='svg', bbox_inches='tight')\n",
    "\n",
    "pth = '../img/CIBERSORT-Plots.png'\n",
    "plt.savefig(pth, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot significant enrichment xCELL\n",
    "mask = (immune['source'] == 'xCell') & (immune['feature'].isin(sigs['xCell']))\n",
    "\n",
    "t = immune[mask]\n",
    "\n",
    "g = sns.catplot(x='cluster', \n",
    "                y='value', \n",
    "                col='feature',\n",
    "                kind='box',\n",
    "                col_wrap=3,\n",
    "                sharex=False,\n",
    "                sharey=False,\n",
    "                data=t)\n",
    "\n",
    "for i in range(len(g.axes)):\n",
    "    g.axes[i].set_xlabel('Hydra Cluster')\n",
    "    g.axes[i].set_ylabel('xCell Enrichment Score')\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5, style='white')\n",
    "\n",
    "interest = [\"B-cells\",\n",
    "            \"CD8+ naive T-cells\",\n",
    "            \"Fibroblasts\"]\n",
    "\n",
    "mask = (immune['source'] == 'xCell') & (immune['feature'].isin(interest))\n",
    "\n",
    "t = immune[mask]\n",
    "\n",
    "g = sns.catplot(x='cluster', \n",
    "                y='value', \n",
    "                col='feature',\n",
    "                kind='box',\n",
    "                col_wrap=3,\n",
    "                col_order=interest,\n",
    "                color='white',\n",
    "                sharex=False,\n",
    "                sharey=False,\n",
    "                data=t)\n",
    "\n",
    "# CD8+\n",
    "sns.swarmplot(x='cluster',\n",
    "              y='value',\n",
    "              color='k',\n",
    "              size=5,\n",
    "              data=t[t['feature'] == 'B-cells'],\n",
    "              ax=g.axes[0])\n",
    "\n",
    "# CD8+\n",
    "sns.swarmplot(x='cluster',\n",
    "              y='value',\n",
    "              color='k',\n",
    "              size=5,\n",
    "              data=t[t['feature'] == 'CD8+ naive T-cells'],\n",
    "              ax=g.axes[1])\n",
    "\n",
    "# Fibroblasts\n",
    "sns.swarmplot(x='cluster',\n",
    "              y='value',\n",
    "              color='k',\n",
    "              size=5,\n",
    "              data=t[t['feature'] == 'Fibroblasts'],\n",
    "              ax=g.axes[2])\n",
    "\n",
    "for i in range(len(g.axes)):\n",
    "    g.axes[i].set_xlabel('Hydra Cluster')\n",
    "    g.axes[i].set_ylabel('xCell Score')\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "\n",
    "pth = '../img/xCell-Plots.svg'\n",
    "plt.savefig(pth, format='svg', bbox_inches='tight')\n",
    "\n",
    "pth = '../img/xCell-Plots.png'\n",
    "plt.savefig(pth, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot significant enrichment ESTIMATE\n",
    "mask = (immune['source'] == 'Estimate') & (immune['feature'].isin(sigs['Estimate']))\n",
    "\n",
    "t = immune[mask]\n",
    "\n",
    "g = sns.catplot(x='cluster', \n",
    "                y='value', \n",
    "                col='feature',\n",
    "                kind='box',\n",
    "                col_wrap=2,\n",
    "                sharex=False,\n",
    "                sharey=False,\n",
    "                data=t)\n",
    "\n",
    "for i in range(len(g.axes)):\n",
    "    g.axes[i].set_xlabel('Hydra Cluster')\n",
    "    g.axes[i].set_ylabel('ESTIMATE Enrichment Score')\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5, style='white')\n",
    "\n",
    "interest = [\"ImmuneScore\",\n",
    "            \"StromalScore\",\n",
    "            \"TumorPurity\"]\n",
    "\n",
    "mask = (immune['source'] == 'Estimate') #& (immune['feature'].isin(sigs['Estimate']))\n",
    "\n",
    "t = immune[mask]\n",
    "\n",
    "g = sns.catplot(x='cluster', \n",
    "                y='value', \n",
    "                col='feature',\n",
    "                kind='box',\n",
    "                col_wrap=3,\n",
    "                col_order=interest,\n",
    "                color='white',\n",
    "                sharex=False,\n",
    "                sharey=False,\n",
    "                data=t)\n",
    "\n",
    "# Immune Score\n",
    "sns.swarmplot(x='cluster',\n",
    "              y='value',\n",
    "              color='k',\n",
    "              size=5,\n",
    "              data=t[t['feature'] == 'ImmuneScore'],\n",
    "              ax=g.axes[0])\n",
    "\n",
    "# Stromal Score\n",
    "sns.swarmplot(x='cluster',\n",
    "              y='value',\n",
    "              color='k',\n",
    "              size=5,\n",
    "              data=t[t['feature'] == 'StromalScore'],\n",
    "              ax=g.axes[1])\n",
    "\n",
    "# Stromal Score\n",
    "sns.swarmplot(x='cluster',\n",
    "              y='value',\n",
    "              color='k',\n",
    "              size=5,\n",
    "              data=t[t['feature'] == 'TumorPurity'],\n",
    "              ax=g.axes[2])\n",
    "\n",
    "\n",
    "for i in range(len(g.axes)):\n",
    "    g.axes[i].set_xlabel('Hydra Cluster')\n",
    "    g.axes[i].set_ylabel('ESTIMATE Score')\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "\n",
    "pth = '../img/ESTIMATE-Plots.svg'\n",
    "plt.savefig(pth, format='svg', bbox_inches='tight')\n",
    "\n",
    "pth = '../img/ESTIMATE-Plots.png'\n",
    "plt.savefig(pth, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ATRX features\n",
    "mask = (features['feature'] == 'ATRX') & (features['value'] == 'deleted')\n",
    "atrx = features.loc[mask, 'root'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for relationship between tumor purity\n",
    "# and clustering. \n",
    "m = np.zeros((2, max(assign[1])))\n",
    "\n",
    "tperc = pd.DataFrame(columns=['sample', '%tumor', 'cluster'])\n",
    "for sample in exp.columns:\n",
    "    root = '-'.join(sample.split('-')[:3])\n",
    "    mask = (features['root'] == root) & (features['feature'] == '%tumor')\n",
    "    v = features.loc[mask, 'value'].item()\n",
    "    if pd.isnull(v):\n",
    "        continue\n",
    "        \n",
    "    c = assign.loc[sample, 1]\n",
    "        \n",
    "    if v > 75:\n",
    "        m[1, c - 1] += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        m[0, c - 1] += 1\n",
    "        \n",
    "    if root in atrx:\n",
    "        print sample, v, assign.loc[sample, 1]\n",
    "        \n",
    "    tperc.loc[len(tperc), :] = [sample, v, c]\n",
    "        \n",
    "tperc['%tumor'] = pd.to_numeric(tperc['%tumor'])\n",
    "\n",
    "print m\n",
    "        \n",
    "_fisher(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot percent tumor values across clusters\n",
    "fig, ax = plt.subplots(1, figsize=(6, 5))\n",
    "\n",
    "sns.boxplot(x='cluster', \n",
    "            y ='%tumor', \n",
    "            data=tperc,\n",
    "            color='white',\n",
    "            ax=ax)\n",
    "\n",
    "sns.swarmplot(x='cluster', \n",
    "              y ='%tumor', \n",
    "              data=tperc,\n",
    "              color='k',\n",
    "              ax=ax)\n",
    "\n",
    "tgroups = []\n",
    "for c, rows in tperc.groupby('cluster'):\n",
    "    tgroups.append(list(rows['%tumor'].values))\n",
    "    \n",
    "ax.set_xlabel('Cluster')\n",
    "ax.set_ylabel('Percent Tumor')\n",
    "\n",
    "pth = '../img/perc-tumor-dist.svg'\n",
    "\n",
    "plt.savefig(pth,\n",
    "            format='svg',\n",
    "            bbox_inches='tight')\n",
    "\n",
    "print kruskal(*tgroups)\n",
    "\n",
    "sp.posthoc_mannwhitney(tgroups, \n",
    "                       p_adjust='holm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create colorbar for heatmap\n",
    "\n",
    "annotations = []\n",
    "\n",
    "atrx_a = []\n",
    "atrx_samples = []\n",
    "\n",
    "hydra_cols = []\n",
    "\n",
    "m3c5000_cols = []\n",
    "m3c500_cols = []\n",
    "\n",
    "for sample in assign.sort_values(1).index.values:\n",
    "    root = '-'.join(sample.split('-')[:3])\n",
    "    cluster = assign.loc[sample, 1]\n",
    "    \n",
    "    if cluster == 1:\n",
    "        hydra_cols.append(\"#3274a1\")\n",
    "        \n",
    "    elif cluster == 2:\n",
    "        hydra_cols.append(\"#e1812c\")\n",
    "        \n",
    "    elif cluster == 3:\n",
    "        hydra_cols.append(\"#3a923a\")\n",
    "        \n",
    "    elif cluster == 4:\n",
    "        hydra_cols.append(\"orange\")\n",
    "     \n",
    "    if root in atrx:\n",
    "        atrx_a.append('red')\n",
    "        atrx_samples.append(sample)\n",
    "         \n",
    "    else:\n",
    "        atrx_a.append('gray')\n",
    "\n",
    "    m3c5000_c = m3c5000.loc[sample, 'consensuscluster']\n",
    "    m3c500_c = m3c500.loc[sample, 'consensuscluster']\n",
    "    \n",
    "    if m3c5000_c == 1:\n",
    "        m3c5000_cols.append('#0e4220')\n",
    "        \n",
    "    elif m3c5000_c == 2:\n",
    "        m3c5000_cols.append('#542788')\n",
    "        \n",
    "    else:\n",
    "        raise ValueError()\n",
    "        \n",
    "    if m3c500_c == 1:\n",
    "        m3c500_cols.append('#7F002B')\n",
    "        \n",
    "    elif m3c500_c == 2:\n",
    "        m3c500_cols.append('#C8C8C8')\n",
    "        \n",
    "    elif m3c500_c == 3:\n",
    "        m3c500_cols.append('#8BC3C0')\n",
    "        \n",
    "    else:\n",
    "        raise ValueError()\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "annotations.append(hydra_cols)\n",
    "annotations.append(m3c5000_cols)\n",
    "annotations.append(m3c500_cols)\n",
    "annotations.append(atrx_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dendrogram for clustering\n",
    "\n",
    "import collections\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import fcluster, cophenet, linkage, dendrogram\n",
    "from scipy.spatial.distance import pdist;\n",
    "\n",
    "def fancy_dendrogram(*args, **kwargs):\n",
    "    max_d = kwargs.pop('max_d', None)\n",
    "    if max_d and 'color_threshold' not in kwargs:\n",
    "        kwargs['color_threshold'] = max_d\n",
    "    annotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "    ddata = dendrogram(*args, **kwargs)\n",
    "\n",
    "    if not kwargs.get('no_plot', False):\n",
    "        plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "        plt.xlabel('sample index or (cluster size)')\n",
    "        plt.ylabel('distance')\n",
    "        for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "            x = 0.5 * sum(i[1:3])\n",
    "            y = d[1]\n",
    "            if y > annotate_above:\n",
    "                plt.plot(x, y, 'o', c=c)\n",
    "                plt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5),\n",
    "                             textcoords='offset points',\n",
    "                             va='top', ha='center')\n",
    "        if max_d:\n",
    "            plt.axhline(y=max_d, c='k')\n",
    "    return ddata;\n",
    "\n",
    "\n",
    "zscore_df = exp.reindex(genes).dropna().apply(lambda x: (x - x.mean()) / x.std(), axis=1) \n",
    "\n",
    "method = 'ward'\n",
    "metric = 'euclidean'\n",
    "\n",
    "row_linkage = hierarchy.linkage(\n",
    "    distance.pdist(zscore_df.values), \n",
    "    method=method, metric=metric)\n",
    "\n",
    "col_linkage = hierarchy.linkage(\n",
    "    distance.pdist(zscore_df.values.T), \n",
    "    method=method, metric=metric);\n",
    "\n",
    "dist = 17\n",
    "\n",
    "fancy_dendrogram(\n",
    "    col_linkage,\n",
    "    truncate_mode='lastp',\n",
    "    p=12,\n",
    "    leaf_rotation=90.,\n",
    "    leaf_font_size=12.,\n",
    "    show_contracted=True,\n",
    "    annotate_above=10,\n",
    "    max_d=dist,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "clusters = fcluster(col_linkage, dist, criterion='distance')\n",
    "\n",
    "cmap = sns.color_palette(\"Set2\", max(clusters))\n",
    "\n",
    "rcolors = [cmap[i - 1] for i in clusters]\n",
    "\n",
    "groups = collections.defaultdict(list)\n",
    "for sample, cluster in zip(zscore_df.columns, clusters):\n",
    "    groups[cluster].append(sample);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster rows and assign function\n",
    "\n",
    "dist = 18\n",
    "\n",
    "fancy_dendrogram(\n",
    "    row_linkage,\n",
    "    truncate_mode='lastp',\n",
    "    p=12,\n",
    "    leaf_rotation=90.,\n",
    "    leaf_font_size=12.,\n",
    "    show_contracted=True,\n",
    "    annotate_above=10,\n",
    "    max_d=dist,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "rclusters = fcluster(row_linkage, dist, criterion='distance')\n",
    "\n",
    "rcmap = sns.color_palette(\"Set2\", max(rclusters))\n",
    "\n",
    "_rcolors = [rcmap[i -1] for i in rclusters]\n",
    "\n",
    "rgroups = collections.defaultdict(list)\n",
    "for sample, cluster in zip(zscore_df.index, rclusters):\n",
    "    rgroups[cluster].append(sample);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "col_order = assign.sort_values(1).index.values\n",
    "\n",
    "g = sns.clustermap(exp.reindex(genes).dropna().reindex(col_order, axis=1),\n",
    "                   col_cluster=False,\n",
    "                   row_linkage=row_linkage,\n",
    "                   col_colors=annotations,\n",
    "                   row_colors=_rcolors,\n",
    "                   z_score=0,\n",
    "                   method='ward',\n",
    "                   center=0,\n",
    "                   cmap=sns.diverging_palette(240, 10, n=7),\n",
    "                   figsize=(10, 10))\n",
    "\n",
    "ax = g.ax_heatmap\n",
    "\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xticks([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "pth = '../img/micro-expression-heatmap.svg'\n",
    "plt.savefig(pth, format='svg', bbox_inches='tight')\n",
    "\n",
    "pth = '../img/micro-expression-heatmap.png'\n",
    "plt.savefig(pth, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "checkpoint = pd.DataFrame(columns=['sample',\n",
    "                                   'cluster', \n",
    "                                   'gene', \n",
    "                                   'value'])\n",
    "\n",
    "for sample in exp.columns:\n",
    "    cluster = assign.loc[sample, 1]\n",
    "    for gene in ['CD274', 'CTLA4']:\n",
    "        checkpoint.loc[len(checkpoint), :] = [sample,\n",
    "                                              cluster, \n",
    "                                              gene, \n",
    "                                              exp.loc[gene, sample]]\n",
    "        \n",
    "checkpoint['value'] = pd.to_numeric(checkpoint['value'])\n",
    "\n",
    "sns.set(font_scale=1.5, style='white')\n",
    "\n",
    "g = sns.catplot(x='cluster', \n",
    "                y='value', \n",
    "                col='gene',\n",
    "                kind='box',\n",
    "                col_wrap=2,\n",
    "                color='white',\n",
    "                sharex=False,\n",
    "                sharey=False,\n",
    "                data=checkpoint)\n",
    "\n",
    "sns.swarmplot(x='cluster',\n",
    "              y='value',\n",
    "              color='k',\n",
    "              size=5,\n",
    "              data=checkpoint[checkpoint['gene'] == 'CD274'],\n",
    "              ax=g.axes[0])\n",
    "\n",
    "# CD8+ T-cells\n",
    "sns.swarmplot(x='cluster',\n",
    "              y='value',\n",
    "              color='k',\n",
    "              size=5,\n",
    "              data=checkpoint[checkpoint['gene'] == 'CTLA4'],\n",
    "              ax=g.axes[1])\n",
    "\n",
    "for i in range(len(g.axes)):\n",
    "    g.axes[i].set_xlabel('Hydra Cluster')\n",
    "    g.axes[i].set_ylabel('Expression (log2(TPM + 1))')\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "\n",
    "pth = '../img/Checkpoint-Plots-V1.svg'\n",
    "plt.savefig(pth, format='svg', bbox_inches='tight')\n",
    "\n",
    "for gene in ['CD274', 'CTLA4']:\n",
    "    print gene\n",
    "    print sp.posthoc_mannwhitney(checkpoint[checkpoint['gene'] == gene],\n",
    "                           val_col='value',\n",
    "                           group_col='cluster',\n",
    "                           p_adjust='fdr_bh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = '../data/meta/ng.2529-S2.xlsx'\n",
    "\n",
    "pugh = pd.read_excel(pth, index_col=0, header=1)\n",
    "\n",
    "burden = pd.DataFrame(columns=['sample', 'burden', 'cluster'])\n",
    "\n",
    "for sample in exp.columns:\n",
    "    \n",
    "    cluster = assign.loc[sample, 1]\n",
    "    root = '-'.join(sample.split('-')[:3])\n",
    "    \n",
    "    try:\n",
    "        bd = pugh.loc[root, 'Nonsilent per Mb']\n",
    "        \n",
    "    except KeyError:\n",
    "        print 'Missing: ', sample\n",
    "        continue\n",
    "        \n",
    "    burden.loc[len(burden), :] = [sample, bd, cluster]\n",
    "    \n",
    "burden['burden'] = pd.to_numeric(burden['burden'])\n",
    "\n",
    "fig, ax = plt.subplots(1, \n",
    "                       figsize=(5, 5))\n",
    "\n",
    "g = sns.boxplot(x='cluster',\n",
    "                y='burden',\n",
    "                data=burden,\n",
    "                color='white',\n",
    "                ax=ax)\n",
    "\n",
    "\n",
    "sns.swarmplot(x='cluster',\n",
    "              y='burden',\n",
    "              data=burden,\n",
    "              color='k',\n",
    "              size=5,\n",
    "              ax=ax)\n",
    "\n",
    "g.set_xlabel('Hydra Cluster')\n",
    "g.set_ylabel('Nonsilent Mutations / Mb')\n",
    "\n",
    "pth = '../img/mutation-burden.svg'\n",
    "plt.savefig(pth, format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data/cluster-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# Clustering Analysis\n",
    "\n",
    "_dir = '../data/cluster-analysis/'\n",
    "\n",
    "cluster_screen = pd.DataFrame(columns=['Method', 'Threshold', 'Clusters', 'Rand Index'])\n",
    "for pth in glob.glob(os.path.join(_dir, 'MYCN-NA-*labels*')):\n",
    "    print(pth)\n",
    "    if \"MYCN-NA-M3C.tsv\" in pth:\n",
    "        continue\n",
    "        \n",
    "    b = os.path.basename(pth)\n",
    "    fields = b.split('-')\n",
    "    \n",
    "    method = fields[2] if fields[2] == 'M3C' else 'Gap Statistic\\nKmeans'\n",
    "    threshold = fields[4]\n",
    "    clusters = fields[-1].replace('.tsv', '')\n",
    "    \n",
    "    \n",
    "    labels = pd.read_csv(pth, sep='\\t')\n",
    "    samples = [x.replace('.', '-') for x in labels.index.values]\n",
    "    labels.index = samples\n",
    "    \n",
    "    if method == 'M3C':\n",
    "        clustering = labels.reindex(assign.index)['consensuscluster'].values\n",
    "            \n",
    "    else:\n",
    "        clustering = labels.reindex(assign.index)['x'].values\n",
    "    \n",
    "    hydra_clusters = assign[1].values\n",
    "    ri = adjusted_rand_score(clustering, hydra_clusters)\n",
    "    \n",
    "    cluster_screen.loc[len(cluster_screen), :] = [method, threshold, clusters, ri]\n",
    "    \n",
    "cluster_screen['Threshold'] = pd.to_numeric(cluster_screen['Threshold'])\n",
    "cluster_screen['Clusters'] = pd.to_numeric(cluster_screen['Clusters'])\n",
    "cluster_screen['Rand Index'] = pd.to_numeric(cluster_screen['Rand Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(8, 6))\n",
    "\n",
    "sns.barplot(x='Threshold', \n",
    "            y='Clusters', \n",
    "            hue='Method',\n",
    "            data=cluster_screen, ax=ax)\n",
    "\n",
    "ax.set_yticks(range(7))\n",
    "ax.set_yticklabels(range(7))\n",
    "ax.set_xlabel(\"Median Absolute Deviation (MAD) Threshold\")\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.5, 1.0), frameon=False)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "sns.pointplot(x='Threshold', \n",
    "            y='Rand Index', \n",
    "            hue='Method', \n",
    "            data=cluster_screen,\n",
    "            ax=ax2)\n",
    "\n",
    "ax2.get_legend().remove()\n",
    "\n",
    "plt.savefig('../img/clustering-screen.svg', \n",
    "            format='svg', \n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event(event):\n",
    "    if pd.isnull(event):\n",
    "        print(\"NULL\")\n",
    "        return np.nan\n",
    "    \n",
    "    events = ['Relapse',\n",
    "              'Death', \n",
    "              'Progression',\n",
    "              'Event',\n",
    "              'Second Malignant Neoplasm']\n",
    "    \n",
    "    if event == 'Censored':\n",
    "        return 0\n",
    "    \n",
    "    elif event in events:\n",
    "        return 1 \n",
    "    \n",
    "    else:\n",
    "        raise ValueError(event)\n",
    "        \n",
    "def get_vital(vital):\n",
    "    if pd.isnull(vital):\n",
    "        print(\"NULL\")\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "    if vital == 'Alive':\n",
    "        return 0\n",
    "    \n",
    "    elif vital == 'Dead':\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(vital)\n",
    "\n",
    "pth = '../data/meta/TARGET_NBL_ClinicalData_Discovery_20170525.xlsx'\n",
    "clinical = pd.read_excel(pth, index_col=0)\n",
    "\n",
    "surv = pd.DataFrame(index=assign.index, \n",
    "                    columns=['OS', 'vital', 'EFS', 'event', 'cluster'])\n",
    "\n",
    "for sample in assign.index.values:\n",
    "    root = '-'.join(sample.split('-')[:3])\n",
    "    if root not in clinical.index:\n",
    "        print \"Missing: \", sample\n",
    "        continue\n",
    "    \n",
    "    OS = clinical.loc[root, 'Overall Survival Time in Days'].item()\n",
    "    vital = get_vital(clinical.loc[root, 'Vital Status'])\n",
    "    \n",
    "    EFS = clinical.loc[root, 'Event Free Survival Time in Days'].item()\n",
    "    event = get_event(clinical.loc[root, 'First Event'])\n",
    "    \n",
    "    cluster = assign.loc[sample, 1]\n",
    "    if cluster == 3:\n",
    "        continue\n",
    "    \n",
    "    surv.loc[sample, :] = [OS, vital, EFS, event, cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survpth = '../data/mycn-na-survival.tsv'\n",
    "surv.to_csv(survpth, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
